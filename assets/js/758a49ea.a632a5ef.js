"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[745],{7293:(e,n,t)=>{t.d(n,{A:()=>S});var o=t(6540),i=t(4848);function s(e){const{mdxAdmonitionTitle:n,rest:t}=function(e){const n=o.Children.toArray(e),t=n.find(e=>o.isValidElement(e)&&"mdxAdmonitionTitle"===e.type),s=n.filter(e=>e!==t),r=t?.props.children;return{mdxAdmonitionTitle:r,rest:s.length>0?(0,i.jsx)(i.Fragment,{children:s}):null}}(e.children),s=e.title??n;return{...e,...s&&{title:s},children:t}}var r=t(4164),l=t(1312),a=t(7559);const c="admonition_xJq3",d="admonitionHeading_Gvgb",h="admonitionIcon_Rf37",u="admonitionContent_BuS1";function p({type:e,className:n,children:t}){return(0,i.jsx)("div",{className:(0,r.A)(a.G.common.admonition,a.G.common.admonitionType(e),c,n),children:t})}function f({icon:e,title:n}){return(0,i.jsxs)("div",{className:d,children:[(0,i.jsx)("span",{className:h,children:e}),n]})}function m({children:e}){return e?(0,i.jsx)("div",{className:u,children:e}):null}function x(e){const{type:n,icon:t,title:o,children:s,className:r}=e;return(0,i.jsxs)(p,{type:n,className:r,children:[o||t?(0,i.jsx)(f,{title:o,icon:t}):null,(0,i.jsx)(m,{children:s})]})}function g(e){return(0,i.jsx)("svg",{viewBox:"0 0 14 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})})}const j={icon:(0,i.jsx)(g,{}),title:(0,i.jsx)(l.A,{id:"theme.admonition.note",description:"The default label used for the Note admonition (:::note)",children:"note"})};function v(e){return(0,i.jsx)(x,{...j,...e,className:(0,r.A)("alert alert--secondary",e.className),children:e.children})}function _(e){return(0,i.jsx)("svg",{viewBox:"0 0 12 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})})}const y={icon:(0,i.jsx)(_,{}),title:(0,i.jsx)(l.A,{id:"theme.admonition.tip",description:"The default label used for the Tip admonition (:::tip)",children:"tip"})};function b(e){return(0,i.jsx)(x,{...y,...e,className:(0,r.A)("alert alert--success",e.className),children:e.children})}function A(e){return(0,i.jsx)("svg",{viewBox:"0 0 14 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})})}const w={icon:(0,i.jsx)(A,{}),title:(0,i.jsx)(l.A,{id:"theme.admonition.info",description:"The default label used for the Info admonition (:::info)",children:"info"})};function T(e){return(0,i.jsx)(x,{...w,...e,className:(0,r.A)("alert alert--info",e.className),children:e.children})}function C(e){return(0,i.jsx)("svg",{viewBox:"0 0 16 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"})})}const k={icon:(0,i.jsx)(C,{}),title:(0,i.jsx)(l.A,{id:"theme.admonition.warning",description:"The default label used for the Warning admonition (:::warning)",children:"warning"})};function P(e){return(0,i.jsx)("svg",{viewBox:"0 0 12 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"})})}const N={icon:(0,i.jsx)(P,{}),title:(0,i.jsx)(l.A,{id:"theme.admonition.danger",description:"The default label used for the Danger admonition (:::danger)",children:"danger"})};const L={icon:(0,i.jsx)(C,{}),title:(0,i.jsx)(l.A,{id:"theme.admonition.caution",description:"The default label used for the Caution admonition (:::caution)",children:"caution"})};const M={...{note:v,tip:b,info:T,warning:function(e){return(0,i.jsx)(x,{...k,...e,className:(0,r.A)("alert alert--warning",e.className),children:e.children})},danger:function(e){return(0,i.jsx)(x,{...N,...e,className:(0,r.A)("alert alert--danger",e.className),children:e.children})}},...{secondary:e=>(0,i.jsx)(v,{title:"secondary",...e}),important:e=>(0,i.jsx)(T,{title:"important",...e}),success:e=>(0,i.jsx)(b,{title:"success",...e}),caution:function(e){return(0,i.jsx)(x,{...L,...e,className:(0,r.A)("alert alert--warning",e.className),children:e.children})}}};function S(e){const n=s(e),t=(o=n.type,M[o]||(console.warn(`No admonition component found for admonition type "${o}". Using Info as fallback.`),M.info));var o;return(0,i.jsx)(t,{...n})}},7531:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>l,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"module-4-vla/capstone-project-autonomous-humanoid","title":"Final Chapter: Capstone Project - The Autonomous Humanoid","description":"Welcome to your final project. You have taught your robot to listen and to think. Now, you will empower it to act with purpose. This capstone is not just about connecting nodes; it\'s about orchestrating a symphony of subsystems to perform complex, real-world tasks autonomously.","source":"@site/docs/module-4-vla/capstone-project-autonomous-humanoid.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/capstone-project-autonomous-humanoid","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/capstone-project-autonomous-humanoid","draft":false,"unlisted":false,"editUrl":"https://github.com/Muskanateeq/Physical-AI-Humanoid-Robotics-Book/tree/main/docs/module-4-vla/capstone-project-autonomous-humanoid.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"capstone-project-autonomous-humanoid","title":"Final Chapter: Capstone Project - The Autonomous Humanoid","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 13: LLM Cognitive Planning","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/llm-cognitive-planning"}}');var i=t(4848),s=t(8453),r=t(7293);const l={id:"capstone-project-autonomous-humanoid",title:"Final Chapter: Capstone Project - The Autonomous Humanoid",sidebar_position:4},a=void 0,c={},d=[{value:"The Scenario: &quot;The Proactive Office Assistant&quot;",id:"the-scenario-the-proactive-office-assistant",level:2},{value:"System Architecture &amp; Interfaces",id:"system-architecture--interfaces",level:2},{value:"Phase 1: The World Model - The Robot&#39;s Memory",id:"phase-1-the-world-model---the-robots-memory",level:2},{value:"Phase 2: The Professional Planner Node",id:"phase-2-the-professional-planner-node",level:2},{value:"Visualizing the Execution Logic",id:"visualizing-the-execution-logic",level:3},{value:"The Code: <code>llm_planner_node_pro_final.py</code>",id:"the-code-llm_planner_node_pro_finalpy",level:3},{value:"Phase 3: Launch &amp; Final Challenge",id:"phase-3-launch--final-challenge",level:2},{value:"Final Capstone Challenge: Advanced Scenarios",id:"final-capstone-challenge-advanced-scenarios",level:3}];function h(e){const n={blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.A,{type:"info",title:"The Grand Challenge",children:(0,i.jsxs)(n.p,{children:["Welcome to your final project. You have taught your robot to listen and to think. Now, you will empower it to ",(0,i.jsx)(n.strong,{children:"act with purpose"}),". This capstone is not just about connecting nodes; it's about orchestrating a symphony of subsystems to perform complex, real-world tasks autonomously."]})}),"\n",(0,i.jsx)(n.h2,{id:"the-scenario-the-proactive-office-assistant",children:'The Scenario: "The Proactive Office Assistant"'}),"\n",(0,i.jsx)(n.p,{children:"Your goal is to program the humanoid robot to act as a truly intelligent office assistant. The mission is an evolution of the last one, with more emphasis on intelligence and robustness:"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:'"A user gives a natural language command. The robot must understand the intent, form a plan, and execute it. If it fails, it must attempt to recover. If it lacks information, it must seek it."'})}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This is the pinnacle of the course, testing your ability to integrate navigation, perception, and manipulation under the guidance of a powerful cognitive engine."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"system-architecture--interfaces",children:"System Architecture & Interfaces"}),"\n",(0,i.jsx)(n.p,{children:"The foundation of a robust system is its architecture. The interfaces between our VLA system and the robot's subsystems must be clear and well-defined."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Subsystem"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Interface Name"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Type"}),(0,i.jsxs)(n.th,{style:{textAlign:"left"},children:["Definition (",(0,i.jsx)(n.code,{children:".srv"})," or ",(0,i.jsx)(n.code,{children:".action"}),")"]})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Navigation"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.code,{children:"/navigate_to_pose"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Action"}),(0,i.jsxs)(n.td,{style:{textAlign:"left"},children:[(0,i.jsx)(n.code,{children:"nav2_msgs/action/NavigateToPose"})," (Standard with Nav2)"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Perception"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.code,{children:"/find_objects"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Service"}),(0,i.jsxs)(n.td,{style:{textAlign:"left"},children:[(0,i.jsx)(n.code,{children:"string object_type --- YourObject[] found_objects"})," (where ",(0,i.jsx)(n.code,{children:"YourObject"})," has an ",(0,i.jsx)(n.code,{children:"id"})," and ",(0,i.jsx)(n.code,{children:"pose"}),")"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Manipulation"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.code,{children:"/pickup_object"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Action"}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.code,{children:"string object_id --- bool success"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Manipulation"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.code,{children:"/place_at_pose"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Action"}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.code,{children:"geometry_msgs/PoseStamped target_pose --- bool success"})})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"phase-1-the-world-model---the-robots-memory",children:"Phase 1: The World Model - The Robot's Memory"}),"\n",(0,i.jsx)(n.p,{children:"A truly intelligent agent needs a memory, or a \"world model.\" This isn't a complex database; for our purpose, it's a simple Python dictionary within our planner node that stores the state of the world as the robot perceives it."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"+---------------------+      +----------------------+      +--------------------+\r\n| Perception System   |-----\x3e|     World Model      |<-----|   LLM Planner      |\r\n| (e.g., YOLO node)   |      | (A Python Dictionary)|      | (Reads state before|\r\n|                     |      |                      |      |   planning)        |\r\n| \"I see bottle_01 at |      | state = {            |      |                    |\r\n|  (x,y,z)\"           |      |  'bottle_01': {      |      | \"Where did I last |\r\n|                     |      |    'pose': ...       |      |  see a bottle?\"    |\r\n+---------------------+      |  }                    |      +--------------------+\r\n                             | }                      |\r\n                             +----------------------+\n"})}),"\n",(0,i.jsx)(n.p,{children:"Our planner will use this world model to make more informed decisions. For example, before planning to pick up an object, it can check its memory to see if it knows where that object is."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"phase-2-the-professional-planner-node",children:"Phase 2: The Professional Planner Node"}),"\n",(0,i.jsx)(n.p,{children:"We will now write the final version of our planner node. This version includes a world model, proper ROS 2 action clients, and a detailed execution loop, complete with an illustrative diagram."}),"\n",(0,i.jsx)(n.h3,{id:"visualizing-the-execution-logic",children:"Visualizing the Execution Logic"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"execute_plan"})," function is the heart of the node. Here is the logic we will implement:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"(inside execute_plan)\r\n      +-----------------+\r\n      |  For each step  |\r\n      |   in LLM plan   |\r\n      +-----------------+\r\n             |\r\n             v\r\n+----------------------------+\r\n|  Route to specific handler |\r\n|  (e.g., handle_navigate)   |\r\n+----------------------------+\r\n             |\r\n             v\r\n+----------------------------+\r\n|  Send goal to ROS 2 Action |\r\n|    Server (e.g., Nav2)     |\r\n+----------------------------+\r\n             |\r\n             v\r\n+----------------------------+\r\n|  Wait for action to finish |\r\n+----------------------------+\r\n             |\r\n             v\r\n+----------------------------+\r\n|   Was it successful?       |\r\n+-------------+--------------+\r\n              |\r\n    +---------+----------+\r\n    | (Yes)              | (No)\r\n    v                    v\r\n+----------------+   +-------------------+\r\n| Continue to    |   | Log Error & Abort |\r\n| next step      |   |       Plan        |\r\n+----------------+   +-------------------+\n"})}),"\n",(0,i.jsxs)(n.h3,{id:"the-code-llm_planner_node_pro_finalpy",children:["The Code: ",(0,i.jsx)(n.code,{children:"llm_planner_node_pro_final.py"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# llm_planner_node_pro_final.py\r\n# ... (imports for rclpy, action clients, services, etc.)\r\n\r\nclass LLMPlannerNodeProFinal(Node):\r\n    def __init__(self):\r\n        super().__init__('llm_planner_node_pro_final')\r\n        self.get_logger().info('THE ULTIMATE LLM PLANNER NODE IS ALIVE.')\r\n        \r\n        # Phase 1: The World Model\r\n        self.world_state = {\r\n            'last_known_objects': [] \r\n        }\r\n\r\n        # ... (OpenAI Client and Action Manifest are the same)\r\n\r\n        # --- Action & Service Clients ---\r\n        self.get_logger().info(\"Connecting to robot's subsystems...\")\r\n        self.nav_client = ActionClient(self, NavigateToPose, '/navigate_to_pose')\r\n        # self.pickup_client = ActionClient(self, PickupObject, '/pickup_object')\r\n        # self.place_client = ActionClient(self, PlaceAtPose, '/place_at_pose')\r\n        # self.find_objects_client = self.create_client(FindObjects, '/find_objects')\r\n        \r\n        # A list of clients to check for availability\r\n        self.action_clients = [self.nav_client, self.pickup_client, self.place_client]\r\n        for client in self.action_clients:\r\n            client.wait_for_server()\r\n        self.get_logger().info(\"SUCCESS: All action servers are online.\")\r\n\r\n        # --- Subscriber ---\r\n        self.subscription = self.create_subscription(String, '/voice_command', self.command_callback, 10)\r\n        self.get_logger().info(\"Ready for your command.\")\r\n\r\n    def command_callback(self, msg):\r\n        # This function gets the plan from the LLM, as before.\r\n        # Let's assume it gets a valid plan called 'plan'.\r\n        # ...\r\n        self.execute_plan(plan)\r\n\r\n    def execute_plan(self, plan):\r\n        \"\"\"\r\n        Orchestrates the execution of the validated plan from the LLM.\r\n        This function follows the logic from our diagram.\r\n        \"\"\"\r\n        self.get_logger().info(\"--- Orchestrating Plan Execution ---\")\r\n        for i, action in enumerate(plan):\r\n            self.get_logger().info(f\"STEP {i+1}/{len(plan)}: {action['function']}({action['parameters']})\")\r\n            \r\n            # Route the action to its handler\r\n            success = self.execute_action(action)\r\n            \r\n            # Critical: Check for failure and abort\r\n            if not success:\r\n                self.get_logger().error(f\"FATAL: Action failed at step {i+1}. Aborting mission.\")\r\n                # Future Enhancement: Trigger a recovery protocol here.\r\n                return\r\n        self.get_logger().info(\"--- MISSION COMPLETE: Plan executed successfully. ---\")\r\n\r\n    def execute_action(self, action):\r\n        \"\"\"\r\n        Routes a single action from the plan to the corresponding\r\n        ROS 2 client and waits for its completion.\r\n        \"\"\"\r\n        function_name = action['function']\r\n        params = action['parameters']\r\n        \r\n        # This is a simple router. In a larger system, this could be more dynamic.\r\n        if function_name == 'navigate_to':\r\n            return self.handle_navigate(params)\r\n        elif function_name == 'find_object':\r\n            return self.handle_find_object(params)\r\n        elif function_name == 'pickup_object':\r\n            return self.handle_pickup(params)\r\n        else:\r\n            self.get_logger().error(f\"Unknown function '{function_name}' in execution router.\")\r\n            return False\r\n\r\n    def handle_navigate(self, params):\r\n        # 1. Get coordinates for the named location\r\n        # goal_pose = self.get_pose_for_location(params['location'])\r\n        # 2. Create the goal message\r\n        # nav_goal = NavigateToPose.Goal(pose=goal_pose)\r\n        # 3. Send the goal and wait\r\n        # future = self.nav_client.send_goal_async(nav_goal)\r\n        # rclpy.spin_until_future_complete(self, future)\r\n        # 4. Return True or False based on the result status\r\n        self.get_logger().info(f\"Executing Navigation to {params['location']}...\")\r\n        return True # Placeholder for a successful action\r\n\r\n    # ... (Implement handle_find_object, handle_pickup, etc. similarly)\r\n    \r\n# ... (main function)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"phase-3-launch--final-challenge",children:"Phase 3: Launch & Final Challenge"}),"\n",(0,i.jsxs)(n.p,{children:["Your final ",(0,i.jsx)(n.code,{children:"ros2 launch"})," file brings this complex system to life. Using ",(0,i.jsx)(n.code,{children:"IncludeLaunchDescription"})," is key to keeping your project organized as it grows."]}),"\n",(0,i.jsx)(n.h3,{id:"final-capstone-challenge-advanced-scenarios",children:"Final Capstone Challenge: Advanced Scenarios"}),"\n",(0,i.jsx)(n.p,{children:'A passing project completes the basic "fetch" task. A truly advanced project demonstrates robustness. Choose one of these challenges to elevate your project.'}),"\n",(0,i.jsxs)(r.A,{type:"success",icon:"\ud83d\ude80",title:"Challenge: Intelligent Error Recovery",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Goal:"})," Don't just abort on failure. Recover."]}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Modify ",(0,i.jsx)(n.code,{children:"execute_plan"})," so that if an action returns ",(0,i.jsx)(n.code,{children:"False"}),", it doesn't just abort."]}),"\n",(0,i.jsxs)(n.li,{children:["It should call a ",(0,i.jsx)(n.strong,{children:"new function"})," ",(0,i.jsx)(n.code,{children:"request_recovery_plan(failed_action, reason)"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["This function will prompt the LLM again, saying something like: ",(0,i.jsxs)(n.em,{children:['"I was executing a plan, but the action ',(0,i.jsx)(n.code,{children:"navigate_to(kitchen)"}),' failed because the path was blocked. Please provide a new plan to achieve the original goal."']})]}),"\n",(0,i.jsx)(n.li,{children:"The robot then attempts this new recovery plan."}),"\n"]})]}),"\n",(0,i.jsxs)(r.A,{type:"success",icon:"\ud83e\udd16",title:"Challenge: Proactive Clarification",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Goal:"})," Don't act on ambiguous commands. Ask for help."]}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:'Create a "confidence score" for the LLM\'s plan. If the user says "get me the thing" and the LLM\'s plan involves an object with a generic name, consider the confidence low.'}),"\n",(0,i.jsxs)(n.li,{children:["If confidence is low, don't execute the plan. Instead, use a Text-to-Speech (TTS) engine (like ",(0,i.jsx)(n.code,{children:"pyttsx3"}),") to make the robot ask a question."]}),"\n",(0,i.jsx)(n.li,{children:'"I see multiple objects on the table. Could you please be more specific?"'}),"\n",(0,i.jsx)(n.li,{children:"The robot then uses your Whisper node to listen for the answer and re-plans with the new, more specific information."}),"\n"]})]}),"\n",(0,i.jsx)(n.p,{children:"You have reached the end of the formal instruction. The path forward is now yours to forge. Build, test, fail, and learn. Good luck."})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var o=t(6540);const i={},s=o.createContext(i);function r(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);