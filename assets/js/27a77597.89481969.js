"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[918],{6924:o=>{o.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-1-ros2/rclpy-bridge","label":"Chapter 1: Bridging Worlds ROS 1 to ROS 2 Bridge","docId":"module-1-ros2/rclpy-bridge","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-1-ros2/ros2-basics","label":"Chapter 2: The Core of ROS 2 Basics","docId":"module-1-ros2/ros2-basics","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-1-ros2/urdf-humanoids","label":"Chapter 3: Describing Your Robot URDF for Humanoids","docId":"module-1-ros2/urdf-humanoids","unlisted":false}],"href":"/Physical-AI-Humanoid-Robotics-Book/docs/category/module-1-the-robotic-nervous-system-ros-2"},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2-simulation/gazebo-physics","label":"Chapter 4: The Physics Engine & Gazebo","docId":"module-2-simulation/gazebo-physics","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2-simulation/unity-rendering","label":"Chapter 5: Photorealism and Interaction in Unity","docId":"module-2-simulation/unity-rendering","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2-simulation/sensor-modeling","label":"Chapter 6: Advanced Sensor Simulation","docId":"module-2-simulation/sensor-modeling","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2-simulation/performance-and-cloud","label":"Chapter 7: Performance, Tuning, and the Cloud","docId":"module-2-simulation/performance-and-cloud","unlisted":false}],"href":"/Physical-AI-Humanoid-Robotics-Book/docs/category/module-2-the-digital-twin-gazebo--unity"},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-aibrain/isaac-sim-environment","label":"Chapter 8: The Sentient Simulator (NVIDIA Isaac Sim)","docId":"module-3-aibrain/isaac-sim-environment","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-aibrain/isaac-ros-vslam","label":"Chapter 9: The Seeing Eye (Hardware-Accelerated VSLAM)","docId":"module-3-aibrain/isaac-ros-vslam","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-aibrain/nav2-bipedal-adaptation","label":"Chapter 10: The Bipedal Navigator (Nav2 Adaptation) for Humanoids","docId":"module-3-aibrain/nav2-bipedal-adaptation","unlisted":false}],"href":"/Physical-AI-Humanoid-Robotics-Book/docs/category/module-3-the-ai-robot-brain-nvidia-isaac"},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/introduction-and-setup","label":"Chapter 11: Introduction and Hardware Setup","docId":"module-4-vla/introduction-and-setup","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/voice-to-action-whisper","label":"Chapter 12: Voice-to-Action with Whisper","docId":"module-4-vla/voice-to-action-whisper","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/llm-cognitive-planning","label":"Chapter 13: LLM Cognitive Planning","docId":"module-4-vla/llm-cognitive-planning","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/capstone-project-autonomous-humanoid","label":"Final Chapter: Capstone Project - The Autonomous Humanoid","docId":"module-4-vla/capstone-project-autonomous-humanoid","unlisted":false}],"href":"/Physical-AI-Humanoid-Robotics-Book/docs/category/module-4-vision-language-action-vla"}]},"docs":{"module-1-ros2/rclpy-bridge":{"id":"module-1-ros2/rclpy-bridge","title":"Chapter 1: Bridging Worlds ROS 1 to ROS 2 Bridge","description":"Bridging the Gap: Connecting ROS 1 to ROS 2","sidebar":"tutorialSidebar"},"module-1-ros2/ros2-basics":{"id":"module-1-ros2/ros2-basics","title":"Chapter 2: The Core of ROS 2 Basics","description":"The Robotic Nervous System: An Introduction to ROS 2","sidebar":"tutorialSidebar"},"module-1-ros2/urdf-humanoids":{"id":"module-1-ros2/urdf-humanoids","title":"Chapter 3: Describing Your Robot URDF for Humanoids","description":"What is URDF? The Blueprint of a Robot","sidebar":"tutorialSidebar"},"module-2-simulation/gazebo-physics":{"id":"module-2-simulation/gazebo-physics","title":"Chapter 4: The Physics Engine & Gazebo","description":"The Digital Twin: A Tale of Two Formats","sidebar":"tutorialSidebar"},"module-2-simulation/performance-and-cloud":{"id":"module-2-simulation/performance-and-cloud","title":"Chapter 7: Performance, Tuning, and the Cloud","description":"Engineering for Performance","sidebar":"tutorialSidebar"},"module-2-simulation/sensor-modeling":{"id":"module-2-simulation/sensor-modeling","title":"Chapter 6: Advanced Sensor Simulation","description":"Simulating Senses: Giving Your Robot Eyes and Ears","sidebar":"tutorialSidebar"},"module-2-simulation/unity-rendering":{"id":"module-2-simulation/unity-rendering","title":"Chapter 5: Photorealism and Interaction in Unity","description":"Beyond Physics: High-Fidelity Rendering","sidebar":"tutorialSidebar"},"module-3-aibrain/isaac-ros-vslam":{"id":"module-3-aibrain/isaac-ros-vslam","title":"Chapter 9: The Seeing Eye (Hardware-Accelerated VSLAM)","description":"Mission Briefing","sidebar":"tutorialSidebar"},"module-3-aibrain/isaac-sim-environment":{"id":"module-3-aibrain/isaac-sim-environment","title":"Chapter 8: The Sentient Simulator (NVIDIA Isaac Sim)","description":"Mission Briefing","sidebar":"tutorialSidebar"},"module-3-aibrain/nav2-bipedal-adaptation":{"id":"module-3-aibrain/nav2-bipedal-adaptation","title":"Chapter 10: The Bipedal Navigator (Nav2 Adaptation) for Humanoids","description":"Mission Briefing","sidebar":"tutorialSidebar"},"module-4-vla/capstone-project-autonomous-humanoid":{"id":"module-4-vla/capstone-project-autonomous-humanoid","title":"Final Chapter: Capstone Project - The Autonomous Humanoid","description":"Welcome to your final project. You have taught your robot to listen and to think. Now, you will empower it to act with purpose. This capstone is not just about connecting nodes; it\'s about orchestrating a symphony of subsystems to perform complex, real-world tasks autonomously.","sidebar":"tutorialSidebar"},"module-4-vla/introduction-and-setup":{"id":"module-4-vla/introduction-and-setup","title":"Chapter 11: Introduction and Hardware Setup","description":"Welcome to Module 4: Vision-Language-Action (VLA). This is where we bridge the gap between human intent and robotic action. By the end of this module, you will have built a system that allows a humanoid robot to understand your voice commands, think about how to execute them, and perform the tasks in the physical world.","sidebar":"tutorialSidebar"},"module-4-vla/llm-cognitive-planning":{"id":"module-4-vla/llm-cognitive-planning","title":"Chapter 13: LLM Cognitive Planning","description":"Your robot can now hear commands. But how does it understand \\"clean the room\\" and know what actions to take? This is where Cognitive Planning using a Large Language Model (LLM) comes in.","sidebar":"tutorialSidebar"},"module-4-vla/voice-to-action-whisper":{"id":"module-4-vla/voice-to-action-whisper","title":"Chapter 12: Voice-to-Action with Whisper","description":"Now that our hardware is configured, it\'s time to build the first part of our VLA pipeline","sidebar":"tutorialSidebar"}}}}')}}]);