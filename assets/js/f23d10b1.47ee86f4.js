"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[822],{7293:(e,n,i)=>{i.d(n,{A:()=>D});var r=i(6540),a=i(4848);function s(e){const{mdxAdmonitionTitle:n,rest:i}=function(e){const n=r.Children.toArray(e),i=n.find(e=>r.isValidElement(e)&&"mdxAdmonitionTitle"===e.type),s=n.filter(e=>e!==i),t=i?.props.children;return{mdxAdmonitionTitle:t,rest:s.length>0?(0,a.jsx)(a.Fragment,{children:s}):null}}(e.children),s=e.title??n;return{...e,...s&&{title:s},children:i}}var t=i(4164),o=i(1312),l=i(7559);const d="admonition_xJq3",c="admonitionHeading_Gvgb",m="admonitionIcon_Rf37",u="admonitionContent_BuS1";function h({type:e,className:n,children:i}){return(0,a.jsx)("div",{className:(0,t.A)(l.G.common.admonition,l.G.common.admonitionType(e),d,n),children:i})}function p({icon:e,title:n}){return(0,a.jsxs)("div",{className:c,children:[(0,a.jsx)("span",{className:m,children:e}),n]})}function g({children:e}){return e?(0,a.jsx)("div",{className:u,children:e}):null}function x(e){const{type:n,icon:i,title:r,children:s,className:t}=e;return(0,a.jsxs)(h,{type:n,className:t,children:[r||i?(0,a.jsx)(p,{title:r,icon:i}):null,(0,a.jsx)(g,{children:s})]})}function f(e){return(0,a.jsx)("svg",{viewBox:"0 0 14 16",...e,children:(0,a.jsx)("path",{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})})}const v={icon:(0,a.jsx)(f,{}),title:(0,a.jsx)(o.A,{id:"theme.admonition.note",description:"The default label used for the Note admonition (:::note)",children:"note"})};function j(e){return(0,a.jsx)(x,{...v,...e,className:(0,t.A)("alert alert--secondary",e.className),children:e.children})}function _(e){return(0,a.jsx)("svg",{viewBox:"0 0 12 16",...e,children:(0,a.jsx)("path",{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})})}const b={icon:(0,a.jsx)(_,{}),title:(0,a.jsx)(o.A,{id:"theme.admonition.tip",description:"The default label used for the Tip admonition (:::tip)",children:"tip"})};function y(e){return(0,a.jsx)(x,{...b,...e,className:(0,t.A)("alert alert--success",e.className),children:e.children})}function z(e){return(0,a.jsx)("svg",{viewBox:"0 0 14 16",...e,children:(0,a.jsx)("path",{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})})}const A={icon:(0,a.jsx)(z,{}),title:(0,a.jsx)(o.A,{id:"theme.admonition.info",description:"The default label used for the Info admonition (:::info)",children:"info"})};function w(e){return(0,a.jsx)(x,{...A,...e,className:(0,t.A)("alert alert--info",e.className),children:e.children})}function S(e){return(0,a.jsx)("svg",{viewBox:"0 0 16 16",...e,children:(0,a.jsx)("path",{fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"})})}const N={icon:(0,a.jsx)(S,{}),title:(0,a.jsx)(o.A,{id:"theme.admonition.warning",description:"The default label used for the Warning admonition (:::warning)",children:"warning"})};function R(e){return(0,a.jsx)("svg",{viewBox:"0 0 12 16",...e,children:(0,a.jsx)("path",{fillRule:"evenodd",d:"M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"})})}const k={icon:(0,a.jsx)(R,{}),title:(0,a.jsx)(o.A,{id:"theme.admonition.danger",description:"The default label used for the Danger admonition (:::danger)",children:"danger"})};const T={icon:(0,a.jsx)(S,{}),title:(0,a.jsx)(o.A,{id:"theme.admonition.caution",description:"The default label used for the Caution admonition (:::caution)",children:"caution"})};const M={...{note:j,tip:y,info:w,warning:function(e){return(0,a.jsx)(x,{...N,...e,className:(0,t.A)("alert alert--warning",e.className),children:e.children})},danger:function(e){return(0,a.jsx)(x,{...k,...e,className:(0,t.A)("alert alert--danger",e.className),children:e.children})}},...{secondary:e=>(0,a.jsx)(j,{title:"secondary",...e}),important:e=>(0,a.jsx)(w,{title:"important",...e}),success:e=>(0,a.jsx)(y,{title:"success",...e}),caution:function(e){return(0,a.jsx)(x,{...T,...e,className:(0,t.A)("alert alert--warning",e.className),children:e.children})}}};function D(e){const n=s(e),i=(r=n.type,M[r]||(console.warn(`No admonition component found for admonition type "${r}". Using Info as fallback.`),M.info));var r;return(0,a.jsx)(i,{...n})}},8383:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module-2-simulation/sensor-modeling","title":"Chapter 6: Advanced Sensor Simulation","description":"Simulating Senses: Giving Your Robot Eyes and Ears","source":"@site/docs/module-2-simulation/3-sensor-modeling.md","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/sensor-modeling","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2-simulation/sensor-modeling","draft":false,"unlisted":false,"editUrl":"https://github.com/Muskanateeq/Physical-AI-Humanoid-Robotics-Book/tree/main/docs/module-2-simulation/3-sensor-modeling.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"sensor-modeling","title":"Chapter 6: Advanced Sensor Simulation"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5: Photorealism and Interaction in Unity","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2-simulation/unity-rendering"},"next":{"title":"Chapter 7: Performance, Tuning, and the Cloud","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2-simulation/performance-and-cloud"}}');var a=i(4848),s=i(8453),t=i(7293);const o={id:"sensor-modeling",title:"Chapter 6: Advanced Sensor Simulation"},l=void 0,d={},c=[{value:"Simulating Senses: Giving Your Robot Eyes and Ears",id:"simulating-senses-giving-your-robot-eyes-and-ears",level:2},{value:"The Sensor Simulation Data Flow",id:"the-sensor-simulation-data-flow",level:3},{value:"Noise Models: Embracing Imperfection",id:"noise-models-embracing-imperfection",level:2},{value:"Simulating Key Sensors in Gazebo",id:"simulating-key-sensors-in-gazebo",level:2},{value:"1. 3D LiDAR",id:"1-3d-lidar",level:3},{value:"2. RGB-D Depth Camera",id:"2-rgb-d-depth-camera",level:3},{value:"3. Inertial Measurement Unit (IMU)",id:"3-inertial-measurement-unit-imu",level:3}];function m(e){const n={code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h2,{id:"simulating-senses-giving-your-robot-eyes-and-ears",children:"Simulating Senses: Giving Your Robot Eyes and Ears"}),"\n",(0,a.jsx)(n.p,{children:"A digital twin is incomplete without a simulated sensor suite. In Gazebo, we can add plugins to our URDF that replicate the data produced by real-world sensors like LiDARs, cameras, and IMUs. This allows us to develop and test perception and navigation algorithms entirely in simulation."}),"\n",(0,a.jsx)(n.h3,{id:"the-sensor-simulation-data-flow",children:"The Sensor Simulation Data Flow"}),"\n",(0,a.jsx)(n.p,{children:'The core principle behind sensor simulation is to take the "ground truth" state from the physics engine, process it, add realistic noise, and publish the result as a standard ROS 2 message.'}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-mermaid",children:'graph TD\r\n    A[Ground Truth World State] --\x3e B{Ideal Sensor Model};\r\n    B --\x3e C{Noise Model};\r\n    C --\x3e D[ROS 2 Message Publisher];\r\n    D --\x3e E[/sensor_topic];\r\n\r\n    subgraph "Physics Engine (Gazebo)"\r\n        A;\r\n    end\r\n    subgraph "Sensor Plugin"\r\n        B;\r\n        C;\r\n        D;\r\n    end\r\n    subgraph "ROS 2 Network"\r\n        E;\r\n    end\n'})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"noise-models-embracing-imperfection",children:"Noise Models: Embracing Imperfection"}),"\n",(0,a.jsx)(n.p,{children:"A perfect sensor doesn't exist. Real sensors have noise, and our simulations must model this to be useful."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Gaussian (Normal) Noise:"})," This is the most common type of noise, affecting most sensor readings. It's modeled by a mean (usually 0.0) and a standard deviation. A larger standard deviation means more noise."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"IMU Drift & Bias:"})," An Inertial Measurement Unit (IMU) is particularly susceptible to two types of error:","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Bias:"})," A constant offset in the readings."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Random Walk (Drift):"})," A slowly accumulating error over time. This is why an IMU alone isn't enough for long-term localization; its position estimate will drift."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"The Gazebo sensor plugins allow you to specify the parameters for these noise models directly in your URDF/SDF."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"simulating-key-sensors-in-gazebo",children:"Simulating Key Sensors in Gazebo"}),"\n",(0,a.jsxs)(n.p,{children:["Here are the SDF snippets required to add the three most common sensors to your robot's URDF. These ",(0,a.jsx)(n.code,{children:"<gazebo>"})," blocks are added at the same level as your ",(0,a.jsx)(n.code,{children:"<link>"})," and ",(0,a.jsx)(n.code,{children:"<joint>"})," tags."]}),"\n",(0,a.jsx)(n.h3,{id:"1-3d-lidar",children:"1. 3D LiDAR"}),"\n",(0,a.jsxs)(n.p,{children:["This example uses a ray-based sensor to simulate a 360-degree LiDAR, publishing ",(0,a.jsx)(n.code,{children:"sensor_msgs/LaserScan"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",metastring:'title="lidar.xacro"',children:'<gazebo reference="base_link">\r\n  <sensor type="ray" name="lidar_sensor">\r\n    <pose>0 0 0.3 0 0 0</pose>\r\n    <visualize>true</visualize>\r\n    <update_rate>10</update_rate>\r\n    <ray>\r\n      <scan>\r\n        <horizontal>\r\n          <samples>720</samples>\r\n          <resolution>1</resolution>\r\n          <min_angle>-3.14159</min_angle>\r\n          <max_angle>3.14159</max_angle>\r\n        </horizontal>\r\n      </scan>\r\n      <range>\r\n        <min>0.1</min>\r\n        <max>30.0</max>\r\n        <resolution>0.01</resolution>\r\n      </range>\r\n      <noise>\r\n        <type>gaussian</type>\r\n        <mean>0.0</mean>\r\n        <stddev>0.01</stddev>\r\n      </noise>\r\n    </ray>\r\n    <plugin name="gazebo_ros_head_hokuyo_controller" filename="libgazebo_ros_ray_sensor.so">\r\n      <ros>\r\n        <namespace>/my_humanoid</namespace>\r\n        <output_type>sensor_msgs/LaserScan</output_type>\r\n        <topic_name>laser_scan</topic_name>\r\n        <frame_name>lidar_link</frame_name>\r\n      </ros>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,a.jsx)(t.A,{type:"info",title:"Environmental Effects: Fog",children:(0,a.jsxs)(n.p,{children:["In a Gazebo ",(0,a.jsx)(n.code,{children:".world"})," file, you can add a ",(0,a.jsx)(n.code,{children:"<fog>"})," block. The LiDAR plugin will automatically interact with this, causing rays to terminate early and simulating the effect of reduced visibility."]})}),"\n",(0,a.jsx)(n.h3,{id:"2-rgb-d-depth-camera",children:"2. RGB-D Depth Camera"}),"\n",(0,a.jsx)(n.p,{children:"This simulates a depth camera like an Intel RealSense, providing a color image, a depth image, and a point cloud."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",metastring:'title="depth_camera.xacro"',children:'<gazebo reference="head_link">\r\n  <sensor type="depth" name="depth_camera_sensor">\r\n    <update_rate>20.0</update_rate>\r\n    <camera name="head">\r\n      <horizontal_fov>1.047</horizontal_fov>\r\n      <image>\r\n        <width>640</width>\r\n        <height>480</height>\r\n        <format>R8G8B8</format>\r\n      </image>\r\n      <clip>\r\n        <near>0.05</near>\r\n        <far>8.0</far>\r\n      </clip>\r\n      <noise>\r\n        <type>gaussian</type>\r\n        <mean>0.0</mean>\r\n        <stddev>0.007</stddev>\r\n      </noise>\r\n    </camera>\r\n    <plugin name="depth_camera_controller" filename="libgazebo_ros_camera.so">\r\n      <ros>\r\n        <namespace>/my_humanoid</namespace>\r\n        <camera_name>depth_cam</camera_name>\r\n        <frame_name>depth_camera_link</frame_name>\r\n        <hack_baseline>0.07</hack_baseline>\r\n      </ros>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,a.jsx)(n.h3,{id:"3-inertial-measurement-unit-imu",children:"3. Inertial Measurement Unit (IMU)"}),"\n",(0,a.jsx)(n.p,{children:"This plugin simulates an IMU, providing orientation, angular velocity, and linear acceleration. The noise parameters are critical here to simulate drift."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",metastring:'title="imu.xacro"',children:'<gazebo reference="torso_link">\r\n  <sensor name="imu_sensor" type="imu">\r\n    <always_on>true</always_on>\r\n    <update_rate>100</update_rate>\r\n    <visualize>true</visualize>\r\n    <imu>\r\n      <angular_velocity>\r\n        <x>\r\n          <noise type="gaussian">\r\n            <mean>0.0</mean>\r\n            <stddev>2e-4</stddev>\r\n            <bias_mean>0.0000075</bias_mean>\r\n            <bias_stddev>0.0000008</bias_stddev>\r\n          </noise>\r\n        </x>\r\n        \x3c!-- ... similar noise for y and z axes ... --\x3e\r\n      </angular_velocity>\r\n      <linear_acceleration>\r\n        <x>\r\n          <noise type="gaussian">\r\n            <mean>0.0</mean>\r\n            <stddev>1.7e-2</stddev>\r\n            <bias_mean>0.1</bias_mean>\r\n            <bias_stddev>0.001</bias_stddev>\r\n          </noise>\r\n        </x>\r\n        \x3c!-- ... similar noise for y and z axes ... --\x3e\r\n      </linear_acceleration>\r\n    </imu>\r\n    <plugin filename="libgazebo_ros_imu_sensor.so" name="imu_plugin">\r\n      <ros>\r\n        <namespace>/my_humanoid</namespace>\r\n        <topic_name>imu/data</topic_name>\r\n        <frame_name>imu_link</frame_name>\r\n      </ros>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var r=i(6540);const a={},s=r.createContext(a);function t(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);